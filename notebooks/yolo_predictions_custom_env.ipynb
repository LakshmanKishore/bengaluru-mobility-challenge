{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.yolo_predictions import YOLO_Pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "yolob = YOLO_Pred('../hackathon-info/colabmodels/best100.onnx','../data.yaml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import deepsort\n",
    "\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "tracker = DeepSort(max_age=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "unable to read video\n"
     ]
    }
   ],
   "source": [
    "input_video_path = '../hackathon-info/processed_videos/stn_hd_1_first_30_seconds_with_5_fps.mp4'\n",
    "output_video_path = '../hackathon-info/processed_videos/stn_hd_1_first_30_seconds_with_5_fps_yolo_model_predictions_best100.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use appropriate codec based on desired output format\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 1, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "\n",
    "while True:\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('unable to read video')\n",
    "        break\n",
    "\n",
    "    pred_image = yolob.predictions(frame)\n",
    "\n",
    "    # cv2.imshow('YOLO',pred_image)\n",
    "    out.write(pred_image)\n",
    "    if cv2.waitKey(1) == 27:\n",
    "        break\n",
    "\n",
    "cv2.destroyAllWindows()\n",
    "cap.release()\n",
    "out.release()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'torch'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 11\u001b[0m\n\u001b[0;32m      8\u001b[0m yolob \u001b[38;5;241m=\u001b[39m YOLO_Pred(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../hackathon-info/colabmodels/best100.onnx\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../data.yaml\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[0;32m     10\u001b[0m \u001b[38;5;66;03m# Initialize Deep SORT tracker\u001b[39;00m\n\u001b[1;32m---> 11\u001b[0m tracker \u001b[38;5;241m=\u001b[39m \u001b[43mDeepSort\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_age\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m5\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     13\u001b[0m input_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../hackathon-info/processed_videos/stn_hd_1_first_30_seconds_with_5_fps.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[0;32m     14\u001b[0m output_video_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m../hackathon-info/processed_videos/stn_hd_1_first_30_seconds_with_5_fps_yolo_model_predictions_best100.mp4\u001b[39m\u001b[38;5;124m'\u001b[39m\n",
      "File \u001b[1;32md:\\anaconda\\envs\\bengaluru_mobility\\lib\\site-packages\\deep_sort_realtime\\deepsort_tracker.py:104\u001b[0m, in \u001b[0;36mDeepSort.__init__\u001b[1;34m(self, max_iou_distance, max_age, n_init, nms_max_overlap, max_cosine_distance, nn_budget, gating_only_position, override_track_class, embedder, half, bgr, embedder_gpu, embedder_model_name, embedder_wts, polygon, today)\u001b[0m\n\u001b[0;32m    102\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mEmbedder \u001b[39m\u001b[38;5;132;01m{\u001b[39;00membedder\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m is not a valid choice.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    103\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m embedder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmobilenet\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m--> 104\u001b[0m     \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeep_sort_realtime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedder_pytorch\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[0;32m    105\u001b[0m         MobileNetv2_Embedder \u001b[38;5;28;01mas\u001b[39;00m Embedder,\n\u001b[0;32m    106\u001b[0m     )\n\u001b[0;32m    108\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membedder \u001b[38;5;241m=\u001b[39m Embedder(\n\u001b[0;32m    109\u001b[0m         half\u001b[38;5;241m=\u001b[39mhalf,\n\u001b[0;32m    110\u001b[0m         max_batch_size\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m16\u001b[39m,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    113\u001b[0m         model_wts_path\u001b[38;5;241m=\u001b[39membedder_wts,\n\u001b[0;32m    114\u001b[0m     )\n\u001b[0;32m    115\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m embedder \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtorchreid\u001b[39m\u001b[38;5;124m'\u001b[39m:\n",
      "File \u001b[1;32md:\\anaconda\\envs\\bengaluru_mobility\\lib\\site-packages\\deep_sort_realtime\\embedder\\embedder_pytorch.py:7\u001b[0m\n\u001b[0;32m      5\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mnumpy\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mnp\u001b[39;00m\n\u001b[0;32m      6\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpkg_resources\u001b[39;00m\n\u001b[1;32m----> 7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[0;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorchvision\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtransforms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m transforms\n\u001b[0;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mdeep_sort_realtime\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01membedder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmobilenetv2_bottle\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MobileNetV2_bottle\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'torch'"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import sys\n",
    "sys.path.append(\"../\")\n",
    "from scripts.yolo_predictions import YOLO_Pred\n",
    "from deep_sort_realtime.deepsort_tracker import DeepSort\n",
    "\n",
    "# Initialize YOLO model\n",
    "yolob = YOLO_Pred('../hackathon-info/colabmodels/best100.onnx', '../data.yaml')\n",
    "\n",
    "# Initialize Deep SORT tracker\n",
    "tracker = DeepSort(max_age=5, )\n",
    "\n",
    "input_video_path = '../hackathon-info/processed_videos/stn_hd_1_first_30_seconds_with_5_fps.mp4'\n",
    "output_video_path = '../hackathon-info/processed_videos/stn_hd_1_first_30_seconds_with_5_fps_yolo_model_predictions_best100.mp4'\n",
    "\n",
    "cap = cv2.VideoCapture(input_video_path)\n",
    "fourcc = cv2.VideoWriter_fourcc(*'mp4v')  # Use appropriate codec based on desired output format\n",
    "out = cv2.VideoWriter(output_video_path, fourcc, 1, (int(cap.get(3)), int(cap.get(4))))\n",
    "\n",
    "# Define counting zones (example coordinates)\n",
    "# zones = {\n",
    "#     'A_to_B': ((100, 200), (300, 400)),  # Define as ((x1, y1), (x2, y2))\n",
    "#     'A_to_C': ((500, 200), (700, 400))\n",
    "# }\n",
    "\n",
    "# Initialize counters\n",
    "vehicle_counts = {'A_to_B': 0, 'A_to_C': 0}\n",
    "\n",
    "while cap.isOpened():\n",
    "    ret, frame = cap.read()\n",
    "    if not ret:\n",
    "        print('Unable to read video')\n",
    "        break\n",
    "\n",
    "    # Get YOLO predictions\n",
    "    detections = yolob.get_detections(frame)\n",
    "\n",
    "    # Format detections for Deep SORT (tlwh: top-left x, top-left y, width, height, confidence, class)\n",
    "    formatted_detections = []\n",
    "    for detection in detections:\n",
    "        x, y, w, h, conf, class_id = detection\n",
    "        formatted_detections.append([x, y, w, h, conf, class_id])\n",
    "\n",
    "    # Update tracker with new detections\n",
    "    tracked_objects = tracker.update_tracks(formatted_detections, frame=frame)\n",
    "\n",
    "    # Draw bounding boxes and update counters\n",
    "    for track in tracked_objects:\n",
    "        if not track.is_confirmed():\n",
    "            continue\n",
    "        track_id = track.track_id\n",
    "        bbox = track.to_tlwh()\n",
    "        class_id = track.det_class\n",
    "        x, y, w, h = map(int, bbox)\n",
    "        color = yolob.generate_colors(class_id)\n",
    "        label = f'{yolob.labels[class_id]} {track_id}'\n",
    "\n",
    "        cv2.rectangle(frame, (x, y), (x + w, y + h), color, 2)\n",
    "        cv2.putText(frame, label, (x, y - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, color, 2)\n",
    "\n",
    "        # Detect direction and update counters\n",
    "        # direction = detect_direction(track, frame)\n",
    "        # if direction:\n",
    "        #     turn_counters[direction] += 1\n",
    "\n",
    "    out.write(frame)\n",
    "\n",
    "    # Display the frame\n",
    "    # cv2.imshow('YOLOv5 + Deep SORT', frame)\n",
    "    # if cv2.waitKey(1) == 27:\n",
    "    #     break\n",
    "\n",
    "# Release resources\n",
    "cap.release()\n",
    "out.release()\n",
    "cv2.destroyAllWindows()\n",
    "\n",
    "# Print the final counts\n",
    "# print('Vehicle Counts:')\n",
    "# for zone, count in vehicle_counts.items():\n",
    "#     print(f'{zone}: {count}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "bengaluru_mobility",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
